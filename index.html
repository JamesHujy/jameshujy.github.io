<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jinyi Hu</title>
  
  <meta name="author" content="Jinyi Hu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jinyi Hu (James)</name>
              </p>
              <p>I am a third-year Ph.D. student at Tsinghua, <a href="https://nlp.csai.tsinghua.edu.cn/">THUNLP</a> lab, advised by <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4033.htm">Maosong Sun</a>. My main research interest lies in multimodal learning, natural language generation, and generative model.
              </p>
              <p>
                During my undergraduate, I interned at Mila Qu√©bec, advised by <a href="https://jian-tang.com/">Jian Tang</a>, and Alibaba Damo, advised by <a href="https://sites.google.com/site/chenboxing/">Boxing Chen</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:hujy369@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Cz70Xr8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/JamesHujy">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpeg" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
              <p>
                B.E.  Department of Computer Science and Technology, <papertitle>Tsinghua University</papertitle>, 2017-2021
                <br>
                <br>
              	Ph.D.  Department of Computer Science and Technology, <papertitle>Tsinghua University</papertitle>, 2021-2026 (expected)
                <br>
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publication</heading>
              <p>
                (*indicates equal contribution)
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr>
      <td style="padding:10px;width:30%;vertical-align:middle">
          <img src='images/viscpm.png' width="100%">
      </td>
      <td style="padding:10px;width:70%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2308.12038.pdf">
          <papertitle>Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages</papertitle>
        </a>
        <br>
        <strong>Jinyi Hu</strong>,
        <a href="https://yaoyuanthu.github.io/">Yuan Yao</a>,
        Chongyi Wang, Shan Wang, Yinxu Pan, Qianyu Chen, Tianyu Yu, Hanghao Wu, Yue Zhao, Haoye Zhang,
        <a href="https://thucsthanxu13.github.io/">Xu Han</a>,
        <a href="https://linyankai.github.io/">Yankai Lin</a>,
        Jiao Xue,
        Dahai Li,
        <a href="https://nlp.csai.tsinghua.edu.cn/~lzy/">Zhiyuan Liu</a>,
        <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4033.htm">Maosong Sun</a>
        <br>
        <em>arxiv</em>, 2023
        <br>
        [<a href="https://arxiv.org/pdf/2308.12038.pdf">paper</a>]
        [<a href="https://github.com/OpenBMB/VisCPM">code (VisCPM)</a>]
        <p></p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px;width:30%;vertical-align:middle">
        <img src='images/muffin.png' width="100%">
    </td>
    <td style="padding:10px;width:70%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2310.00653.pdf">
          <papertitle>Reformulating Vision-Language Foundation Models and Datasets Towards Universal Multimodal Assistants</papertitle>
        </a>
        <br>
        <a href="https://tianyu-yu.com/">Tianyu Yu</a>,
        <strong>Jinyi Hu*</strong>,
        <a href="https://yaoyuanthu.github.io/">Yuan Yao</a>,
        Haoye Zhang, Yue Zhao, Chongyi Wang, Shan Wang, Yinxv Pan, Jiao Xue, Dahai Li, 
        <a href="https://nlp.csai.tsinghua.edu.cn/~lzy/">Zhiyuan Liu</a>,
        <a href="https://www.sigs.tsinghua.edu.cn/zht_en/main.htm">Hai-Tao Zheng, </a>
        <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4033.htm">Maosong Sun</a>
        <br>
        <em>arxiv</em>, 2023
        <br>
        [<a href="https://arxiv.org/pdf/2310.00653.pdf">paper</a>]
        [<a href="https://github.com/thunlp/muffin">code (Muffin)</a>]
        [<a href="https://huggingface.co/datasets/Yirany/UniMM-Chat">dataset (UniMM-Chat)</a>]
        <p></p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px;width:30%;vertical-align:middle">
        <img src='images/iap.png' width="100%">
    </td>
    <td style="padding:10px;width:70%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2305.11540.pdf">
          <papertitle>Efficient Cross-Lingual Transfer for Chinese Stable Diffusion with Images as Pivots</papertitle>
        </a>
        <br>
        <strong>Jinyi Hu</strong>,
        <a href="https://thucsthanxu13.github.io/">Xu Han</a>,
        <a href="https://www.microsoft.com/en-us/research/people/xiaoyuanyi/">Xiaoyuan Yi</a>,
        Yutong Chen,
        Wenhao Li</a>,
        <a href="https://nlp.csai.tsinghua.edu.cn/~lzy/">Zhiyuan Liu</a>,
        <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4033.htm">Maosong Sun</a>
        <br>
        <em>arxiv</em>, 2023
        <br>
        [<a href="https://arxiv.org/pdf/2305.11540.pdf">paper</a>]
        <p></p>
      </td>
    </tr>

    <tr>
      <td style="padding:10px;width:30%;vertical-align:middle">
        <img src='images/della.png' width="100%">
      </td>
    <td style="padding:10px;width:70%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2207.06130.pdf">
          <papertitle>Fuse It More Deeply! A Variational Transformer with Layer-Wise Latent Variable Inference for Text Generation</papertitle>
        </a>
        <br>
        <strong>Jinyi Hu</strong>,
        <a href="https://www.microsoft.com/en-us/research/people/xiaoyuanyi/">Xiaoyuan Yi</a>,
        Wenhao Li</a>,
        <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4033.htm">Maosong Sun</a>,
        Xing Xie
        <br>
        <em>NAACL</em> 2022
        <br>
        [<a href="https://arxiv.org/pdf/2207.06130.pdf">paper</a>]
        [<a href="https://github.com/OpenVLG/DELLA">code (DELLA)</a>]
        <p></p>
      </td>
    </tr>
    
    <tr>
      <td style="padding:10px;width:30%;vertical-align:middle">
        <img src='images/care.png' width="100%">
      </td>
    <td style="padding:10px;width:70%;vertical-align:middle">
      <a href="https://arxiv.org/pdf/2211.07164.pdf">
        <papertitle>Evade the Trap of Mediocrity: Promoting Diversity and Novelty in Text Generation via Concentrating Attention</papertitle>
      </a>
      <br>
      Wenhao Li</a>,
      <a href="https://www.microsoft.com/en-us/research/people/xiaoyuanyi/">Xiaoyuan Yi</a>,
      <strong>Jinyi Hu</strong>,
      <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4033.htm">Maosong Sun</a>,
      Xing Xie
      <br>
      <em>EMNLP</em> 2022
      <br>
      [<a href="https://arxiv.org/pdf/2211.07164.pdf">paper</a>]
      <p></p>
    </td>
    </tr>

    <tr>
      <td style="padding:10px;width:30%;vertical-align:middle">
        <img src='images/trace.png' width="100%">
      </td>
    <td style="padding:10px;width:70%;vertical-align:middle">
      <a href="https://arxiv.org/pdf/2210.12409.pdf">
        <papertitle>Recurrence Boosts Diversity! Revisiting Recurrent Latent Variable in Transformer-Based Variational AutoEncoder for Diverse Text Generation</papertitle>
      </a>
      <br>
      <strong>Jinyi Hu</strong>,
      <a href="https://www.microsoft.com/en-us/research/people/xiaoyuanyi/">Xiaoyuan Yi</a>,
      Wenhao Li</a>,
      <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4033.htm">Maosong Sun</a>,
      Xing Xie
      <br>
      <em>Findings of EMNLP</em> 2022
      <br>
      [<a href="https://arxiv.org/pdf/2210.12409.pdf">paper</a>]
      <p></p>
    </td>
    </tr>

    <tr>
      <td style="padding:10px;width:30%;vertical-align:middle">
        <img src='images/asrg.png' width="100%">
      </td>
    <td style="padding:10px;width:70%;vertical-align:middle">
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17497/17304">
        <papertitle>Aspect-level sentiment-controllable review generation with mutual learning framework</papertitle>
      </a>
      <br>
      <a href="http://nlp.csai.tsinghua.edu.cn/~chm/">Huimin Chen</a>,
      <a href="https://linyankai.github.io/">Yankai Lin</a>,
      <a href="https://fanchao-qi.github.io/">Fanchao Qi</a>,
      <strong>Jinyi Hu</strong>,
      <a href="https://www.lpeng.net/">Peng Li</a>,
      Jie Zhou,
      <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4033.htm">Maosong Sun</a>
      <br>
      <em>AAAI</em> 2021
      <br>
      [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17497/17304">paper</a>]
      <p></p>
    </td>
    </tr>
    
    <tr>
      <td style="padding:10px;width:30%;vertical-align:middle">
        <img src='images/elv.png' width="100%">
      </td>
    <td style="padding:10px;width:70%;vertical-align:middle">
      <a href="https://proceedings.neurips.cc/paper/2020/file/4be2c8f27b8a420492f2d44463933eb6-Paper.pdf">
        <papertitle>Towards interpretable natural language understanding with explanations as latent variables</papertitle>
      </a>
      <br>
      <a href="https://michaelzhouwang.github.io/">Wangchunshu Zhou*</a>,
      <strong>Jinyi Hu*</strong>,
      <a href="https://hanlin-zhang.com/">Hanlin Zhang*</a>,
      <a href="https://lemondan.github.io/">Xiaodan Liang</a>,
      <a href="https://www.cs.tsinghua.edu.cn/csen/info/1180/4033.htm">Maosong Sun</a>,
      <a href="https://www.microsoft.com/en-us/research/people/cxiong/">Chenyan Xiong</a>,
      <a href="https://jian-tang.com/">Jian Tang</a>,
      <br>
      <em>NeurIPS</em> 2020
      <br>
      [<a href="https://proceedings.neurips.cc/paper/2020/file/4be2c8f27b8a420492f2d44463933eb6-Paper.pdf">paper</a>]
      [<a href="https://github.com/JamesHujy/ELV">code</a>]
      <p></p>
    </td>
    </tr>
  </tr>
        </tbody></table>
        
        <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Service</heading>
                  <p>
                    Reviewer: EMNLP 2023, ACL 2023, ACL 2022, EMNLP 2022, ACL 2021, ENNLP 2021
                  </p>
                </td>
              </tr>
            </tbody>
        </table>

        <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Honors & Awards</heading>
                  <ul>
                    <li>Longhu Scholarship, 2023</li>
                    <li>Comprehensive Scholarship, 2022</li>
                    <li>Merit Student in Beijing, 2020</li>
                    <li>Tang Lixin Scholarship, 2020</li>
                    <li>Evergrande Scholarship, 2018</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

				<table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Miscellaneous</heading>
                  <p>
                    I usually go to the gym during the spare time. I also love NBA, Snooker and Tennis, a big fan of LeBron James, Ronnie O'Sullivan and Roger Federer.
                  </p>
                </td>
              </tr>
            </tbody>
        </table>
					
					
        </tbody></table>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table> -->
      </td>
    </tr>
  </table>
</body>

</html>
